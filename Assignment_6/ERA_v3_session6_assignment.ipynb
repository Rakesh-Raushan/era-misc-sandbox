{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0m2JWFliFfKT"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_value = 0.1\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #INPUT BLOCK\n",
    "        self.convblock1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3), #inch=1, outch=8, size=26, rf=3, j=1\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        )\n",
    "    \n",
    "        #CONV BLOCK 1\n",
    "        self.convblock2 = nn.Sequential(\n",
    "            nn.Conv2d(8,16, 3), #inch=8, outch=16, size=24, rf=5, j=1\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        )\n",
    "        self.convblock3 = nn.Sequential(\n",
    "            nn.Conv2d(16,16, 3), #inch=16, inout=16, size=22, rf=7, j=1\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        )\n",
    "\n",
    "        self.convblock31 = nn.Sequential(\n",
    "            nn.Conv2d(16,16, 3), #inch=16, inout=16, size=20, rf=9, j=1\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        )\n",
    "        # TRANSITION BLOCK\n",
    "        #POOL LAYER\n",
    "        self.convblock4 = nn.Sequential(\n",
    "            nn.Conv2d(16,8,3), #inch16, outch=8, size=18, rf=11, j=1\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 9, rf=12, j=2\n",
    "    \n",
    "        #CONV BLOCK 2\n",
    "        self.convblock5 = nn.Sequential(\n",
    "            nn.Conv2d(8,16,3), #inch=8, outch=16, size=7, rf=16, j=2\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        )\n",
    "        self.convblock6 = nn.Sequential(\n",
    "            nn.Conv2d(16,16,3), #inch=16, outch=16, size=5, rf=20, j=2\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        )\n",
    "\n",
    "        # OUTPUT BLOCK\n",
    "        self.convblock7 = nn.Sequential(\n",
    "            nn.Conv2d(16,32,3), #inch=16, outch=32, size=3, rf=24, j=2\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        )\n",
    "        self.convblock8 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=10, kernel_size=(1, 1), padding=0, bias=False)\n",
    "        ) # output_size = 5 #inch=32, outch=10, size=1, rf=28, j=2\n",
    "        self.gap = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "            \n",
    "        # self.dropout = nn.Dropout(0.1)\n",
    "        #LINEAR LAYER\n",
    "        # self.fc_layer = nn.Linear(32*18*18, 10) #replaced with Adaptive pool\n",
    "\n",
    "    def forward(self, x):\n",
    "        # BLOCK 1\n",
    "        x = self.convblock1(x)\n",
    "        x = self.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = self.convblock31(x)\n",
    "        # x = self.dropout(x)\n",
    "        # TRANSITION\n",
    "        x = self.convblock4(x)\n",
    "        x = self.pool1(x)\n",
    "        # BLOCK 2\n",
    "        x = self.convblock5(x)\n",
    "        x = self.convblock6(x)\n",
    "        # x = self.dropout(x)\n",
    "        # OUTPUT\n",
    "        x = self.convblock7(x)\n",
    "        x = self.convblock8(x)\n",
    "        x = self.gap(x)\n",
    "        \n",
    "        x = x.view(-1, 10)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use MPS?: True\n"
     ]
    }
   ],
   "source": [
    "SEED = 1\n",
    "\n",
    "# Apple metal or Nvidia CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_mps = torch.mps.is_available()\n",
    "\n",
    "# seed for repeatablility:\n",
    "\n",
    "# for all devices\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# for specific acc\n",
    "if use_cuda:\n",
    "    print(f\"Use CUDA?:{use_cuda}\")\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "elif use_mps:\n",
    "    print(f\"Use MPS?: {use_mps}\")\n",
    "    torch.mps.manual_seed(SEED)\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Phase transformations\n",
    "train_transforms = transforms.Compose([\n",
    "                                      #  transforms.Resize((28, 28)),\n",
    "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
    "                                       transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n",
    "                                       # Note the difference between (0.1307) and (0.1307,)\n",
    "                                       ])\n",
    "\n",
    "# Test Phase transformations\n",
    "test_transforms = transforms.Compose([\n",
    "                                      #  transforms.Resize((28, 28)),\n",
    "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                       ])\n",
    "\n",
    "train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n",
    "test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)\n",
    "\n",
    "\n",
    "dataloader_args = dict(shuffle=True,\n",
    "                       batch_size=128,\n",
    "                       num_workers=4,\n",
    "                       pin_memory=True) \\\n",
    "                                        if use_cuda or use_mps else \\\n",
    "                    dict(shuffle=True,\n",
    "                         batch_size=128)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train,\n",
    "                                           **dataloader_args)\n",
    "test_loader = torch.utils.data.DataLoader(test,\n",
    "                                          **dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /Users/rraushan/courses/ERA_V3_Assignments/eravenv/lib/python3.12/site-packages (1.5.1)\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 26, 26]              80\n",
      "       BatchNorm2d-2            [-1, 8, 26, 26]              16\n",
      "              ReLU-3            [-1, 8, 26, 26]               0\n",
      "           Dropout-4            [-1, 8, 26, 26]               0\n",
      "            Conv2d-5           [-1, 16, 24, 24]           1,168\n",
      "       BatchNorm2d-6           [-1, 16, 24, 24]              32\n",
      "              ReLU-7           [-1, 16, 24, 24]               0\n",
      "           Dropout-8           [-1, 16, 24, 24]               0\n",
      "            Conv2d-9           [-1, 16, 22, 22]           2,320\n",
      "      BatchNorm2d-10           [-1, 16, 22, 22]              32\n",
      "             ReLU-11           [-1, 16, 22, 22]               0\n",
      "          Dropout-12           [-1, 16, 22, 22]               0\n",
      "           Conv2d-13           [-1, 16, 20, 20]           2,320\n",
      "      BatchNorm2d-14           [-1, 16, 20, 20]              32\n",
      "             ReLU-15           [-1, 16, 20, 20]               0\n",
      "          Dropout-16           [-1, 16, 20, 20]               0\n",
      "           Conv2d-17            [-1, 8, 18, 18]           1,160\n",
      "      BatchNorm2d-18            [-1, 8, 18, 18]              16\n",
      "             ReLU-19            [-1, 8, 18, 18]               0\n",
      "        MaxPool2d-20              [-1, 8, 9, 9]               0\n",
      "           Conv2d-21             [-1, 16, 7, 7]           1,168\n",
      "      BatchNorm2d-22             [-1, 16, 7, 7]              32\n",
      "             ReLU-23             [-1, 16, 7, 7]               0\n",
      "          Dropout-24             [-1, 16, 7, 7]               0\n",
      "           Conv2d-25             [-1, 16, 5, 5]           2,320\n",
      "      BatchNorm2d-26             [-1, 16, 5, 5]              32\n",
      "             ReLU-27             [-1, 16, 5, 5]               0\n",
      "          Dropout-28             [-1, 16, 5, 5]               0\n",
      "           Conv2d-29             [-1, 32, 3, 3]           4,640\n",
      "      BatchNorm2d-30             [-1, 32, 3, 3]              64\n",
      "             ReLU-31             [-1, 32, 3, 3]               0\n",
      "          Dropout-32             [-1, 32, 3, 3]               0\n",
      "           Conv2d-33             [-1, 10, 3, 3]             320\n",
      "AdaptiveAvgPool2d-34             [-1, 10, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 15,752\n",
      "Trainable params: 15,752\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.99\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 1.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "elif use_mps:\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model = Net()\n",
    "\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# define metrics to calc\n",
    "\n",
    "train_losses = []\n",
    "train_acc = []\n",
    "\n",
    "test_losses = []\n",
    "test_acc = []\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer):\n",
    "    # set model to train mode\n",
    "    model.train()\n",
    "\n",
    "    # tqdm iterator\n",
    "    pbar = tqdm(train_loader)\n",
    "\n",
    "    # correct and processed vars\n",
    "    correct = 0\n",
    "    processed = 0\n",
    "\n",
    "    # loop on batches of data\n",
    "    for batch_idx, (data,target) in enumerate(pbar):\n",
    "        #send data, targte to training device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Initialize grad to zero for the fresh batch grad accumuation\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # pred with model\n",
    "        y_pred = model(data)\n",
    "\n",
    "        # calc loss\n",
    "        batch_loss = F.nll_loss(y_pred, target)\n",
    "        train_losses.append(batch_loss)\n",
    "\n",
    "        # backprop loss to calc and acc grad w.r.t loss of batch\n",
    "        batch_loss.backward()\n",
    "        \n",
    "        # update weights as per losses seen in this batch\n",
    "        optimizer.step()\n",
    "\n",
    "        # calculate correct pred count and acc for batch\n",
    "        pred_labels = y_pred.argmax(dim=1, keepdim=True)\n",
    "        correct_count_batch = pred_labels.eq(target.view_as(pred_labels)).sum().item()\n",
    "\n",
    "        # update total correct and total processed so far\n",
    "        correct+= correct_count_batch\n",
    "        processed+= len(data)\n",
    "\n",
    "        # set pbar desc\n",
    "        pbar.set_description(desc=f'batch Loss = {batch_loss.item()} batch_id = {batch_idx} accuracy = {100*correct/processed:.02f}'\n",
    "                            )\n",
    "        #append train acc\n",
    "        train_acc.append(100*correct/processed)\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    # set model to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # define var to calc correct and processed\n",
    "    correct = 0\n",
    "    processed = 0\n",
    "    test_loss = 0 # seeing loss as the code runs has no value for test\n",
    "\n",
    "    # set a no grad context\n",
    "    with torch.no_grad():\n",
    "        for data,target in test_loader:\n",
    "            #send data, target to device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "    \n",
    "            # do pred\n",
    "            y_pred = model(data)\n",
    "    \n",
    "            #calc loss for batch as summed and update total test loss\n",
    "            batch_loss = F.nll_loss(y_pred, target, reduction='sum').item()\n",
    "            test_loss+= batch_loss\n",
    "            # collect loss\n",
    "            test_losses.append(batch_loss)\n",
    "    \n",
    "            # count correct\n",
    "            pred_labels = y_pred.argmax(dim=1, keepdim=True)\n",
    "            correct_batch = pred_labels.eq(target.view_as(pred_labels)).sum().item()\n",
    "    \n",
    "            #update correct\n",
    "            correct+= correct_batch\n",
    "            processed+= len(data)\n",
    "\n",
    "    # avg loss on test makes more sense to avg it\n",
    "    test_loss/= processed\n",
    "    # collect avg losses\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print(f'\\n Test set avg loss: {test_loss:.4f} \\\n",
    "                Accuracy: {correct}/{processed}, {100*correct/processed:.2f}'\n",
    "         )\n",
    "\n",
    "    test_acc.append(100*correct/processed)\n",
    "    return test_loss\n",
    "        \n",
    "\n",
    "# Note it is little weird in the sense that train losses and acc are \n",
    "# collected for each batch in the above code but test losses and acc are\n",
    "# collected for each epoch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.12355833500623703 batch_id = 468 accuracy = 89.07: 100%|█| 469/469 [00:13<00:00, 34.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0737                 Accuracy: 9810/10000, 98.10\n",
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.05688127875328064 batch_id = 468 accuracy = 97.52: 100%|█| 469/469 [00:11<00:00, 41.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0441                 Accuracy: 9876/10000, 98.76\n",
      "EPOCH: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.049336958676576614 batch_id = 468 accuracy = 98.02: 100%|█| 469/469 [00:10<00:00, 44.06it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0349                 Accuracy: 9905/10000, 99.05\n",
      "EPOCH: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.03311590105295181 batch_id = 468 accuracy = 98.25: 100%|█| 469/469 [00:10<00:00, 43.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0325                 Accuracy: 9897/10000, 98.97\n",
      "EPOCH: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.016051035374403 batch_id = 468 accuracy = 98.41: 100%|███| 469/469 [00:10<00:00, 44.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0264                 Accuracy: 9922/10000, 99.22\n",
      "EPOCH: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.03056023083627224 batch_id = 468 accuracy = 98.47: 100%|█| 469/469 [00:10<00:00, 42.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0282                 Accuracy: 9911/10000, 99.11\n",
      "EPOCH: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.16768985986709595 batch_id = 468 accuracy = 98.63: 100%|█| 469/469 [00:10<00:00, 44.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0276                 Accuracy: 9906/10000, 99.06\n",
      "EPOCH: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.00619245320558548 batch_id = 468 accuracy = 98.77: 100%|█| 469/469 [00:10<00:00, 43.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0245                 Accuracy: 9925/10000, 99.25\n",
      "EPOCH: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.006135950330644846 batch_id = 468 accuracy = 98.82: 100%|█| 469/469 [00:10<00:00, 43.67it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0223                 Accuracy: 9928/10000, 99.28\n",
      "EPOCH: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.023698588833212852 batch_id = 468 accuracy = 98.75: 100%|█| 469/469 [00:10<00:00, 44.03it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0244                 Accuracy: 9925/10000, 99.25\n",
      "EPOCH: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.07484211027622223 batch_id = 468 accuracy = 98.81: 100%|█| 469/469 [00:10<00:00, 43.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0226                 Accuracy: 9935/10000, 99.35\n",
      "EPOCH: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.056699950248003006 batch_id = 468 accuracy = 98.84: 100%|█| 469/469 [00:10<00:00, 43.63it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0216                 Accuracy: 9940/10000, 99.40\n",
      "EPOCH: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.030623765662312508 batch_id = 468 accuracy = 98.91: 100%|█| 469/469 [00:10<00:00, 43.82it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0222                 Accuracy: 9930/10000, 99.30\n",
      "EPOCH: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.004612436983734369 batch_id = 468 accuracy = 98.89: 100%|█| 469/469 [00:10<00:00, 43.96it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0243                 Accuracy: 9924/10000, 99.24\n",
      "EPOCH: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.06747055798768997 batch_id = 468 accuracy = 98.94: 100%|█| 469/469 [00:11<00:00, 42.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0206                 Accuracy: 9932/10000, 99.32\n",
      "EPOCH: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.054090797901153564 batch_id = 468 accuracy = 99.01: 100%|█| 469/469 [00:10<00:00, 43.50it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0208                 Accuracy: 9934/10000, 99.34\n",
      "EPOCH: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.0070099979639053345 batch_id = 468 accuracy = 98.95: 100%|█| 469/469 [00:11<00:00, 39.97it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0221                 Accuracy: 9926/10000, 99.26\n",
      "EPOCH: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.014665688388049603 batch_id = 468 accuracy = 98.97: 100%|█| 469/469 [00:10<00:00, 43.71it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0193                 Accuracy: 9942/10000, 99.42\n",
      "EPOCH: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.015031891874969006 batch_id = 468 accuracy = 99.02: 100%|█| 469/469 [00:10<00:00, 44.16it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0214                 Accuracy: 9933/10000, 99.33\n",
      "EPOCH: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "atch Loss = 0.004560594912618399 batch_id = 468 accuracy = 99.03: 100%|█| 469/469 [00:10<00:00, 43.99it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test set avg loss: 0.0230                 Accuracy: 9932/10000, 99.32\n"
     ]
    }
   ],
   "source": [
    "# initialize model on device\n",
    "model = Net().to(device)\n",
    "\n",
    "# initialize optimizer with model params and lr\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.02, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# let's try a lr scheduler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "# step scheduler\n",
    "# scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "\n",
    "# Set total epochs\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'EPOCH: {epoch}')\n",
    "    train(model, device, train_loader, optimizer)\n",
    "    test_loss = test(model, device, test_loader)\n",
    "    scheduler.step(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "So5uk4EkHW6R"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
